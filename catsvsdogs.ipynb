{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math\n",
    "import numpy as np\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclassification task\n",
    "# cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'data/train/'\n",
    "VALIDATION_DATA_DIR = 'data/val/'\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        TRAIN_DATA_DIR,\n",
    "                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        seed=12345,\n",
    "                        class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "                        VALIDATION_DATA_DIR,\n",
    "                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/fcwnfr4d06z44tl7ddmtdsrr0000gn/T/ipykernel_93405/670373825.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.7909 - acc: 0.6680 - val_loss: 0.2186 - val_acc: 0.9280\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.2732 - acc: 0.8980 - val_loss: 0.1296 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.1622 - acc: 0.9300 - val_loss: 0.1112 - val_acc: 0.9700\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1280 - acc: 0.9580 - val_loss: 0.0944 - val_acc: 0.9600\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.0845 - acc: 0.9760 - val_loss: 0.0825 - val_acc: 0.9680\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.0886 - acc: 0.9720 - val_loss: 0.0778 - val_acc: 0.9640\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.0836 - acc: 0.9700 - val_loss: 0.0723 - val_acc: 0.9700\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0631 - acc: 0.9840 - val_loss: 0.0698 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0629 - acc: 0.9800 - val_loss: 0.0678 - val_acc: 0.9740\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.0706 - acc: 0.9740 - val_loss: 0.0669 - val_acc: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123823610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_maker()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= tf.keras.optimizers.Adam(),\n",
    "              metrics=['acc'])\n",
    "num_steps = math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE)              \n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = num_steps,\n",
    "                    epochs=10,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# VARIABLES\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "VALIDATION_DATA_DIR = 'data/val'\n",
    "VALIDATION_BATCH_SIZE = 64\n",
    "\n",
    "# DATA GENERATORS\n",
    "validation_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        VALIDATION_DATA_DIR,\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        batch_size=VALIDATION_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "ground_truth = validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "with CustomObjectScope(\n",
    "    {'GlorotUniform': glorot_uniform()}):\n",
    "    model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "['cat/cat.10060.jpg', 'cat/cat.10117.jpg', 'cat/cat.1024.jpg', 'cat/cat.10327.jpg', 'cat/cat.10346.jpg', 'cat/cat.10380.jpg', 'cat/cat.1041.jpg', 'cat/cat.10428.jpg', 'cat/cat.10434.jpg', 'cat/cat.10455.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Let's view the names of the files.\n",
    "filenames = validation_generator.filenames\n",
    "print(len(filenames))\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "ground_truth = validation_generator.classes\n",
    "print(ground_truth[:10])\n",
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "label_to_index = validation_generator.class_indices\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cat', 1: 'dog'}\n"
     ]
    }
   ],
   "source": [
    "index_to_label = dict((i,j) for (j,i) in label_to_index.items())\n",
    "print(index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/fcwnfr4d06z44tl7ddmtdsrr0000gn/T/ipykernel_93405/4095933862.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(validation_generator,\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(validation_generator,\n",
    "                                      steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999356e-01 6.4100700e-06]\n",
      " [9.9999571e-01 4.2538677e-06]\n",
      " [9.9997973e-01 2.0304913e-05]\n",
      " [9.8737216e-01 1.2627833e-02]\n",
      " [9.9902391e-01 9.7609230e-04]\n",
      " [8.5441142e-01 1.4558858e-01]\n",
      " [9.9979740e-01 2.0260277e-04]\n",
      " [9.9998951e-01 1.0452185e-05]\n",
      " [9.9927860e-01 7.2139746e-04]\n",
      " [9.9992216e-01 7.7881436e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = []\n",
    "for prediction in predictions:\n",
    "    prediction_index.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, ground_truth):\n",
    "    total = 0\n",
    "    for i,j in zip(predictions, ground_truth):\n",
    "        if i==j:\n",
    "            total+=1\n",
    "    return (total*1.0)/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction_index, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more compact analysis\n",
    "prediction_table = {}\n",
    "for index, val in enumerate(predictions):\n",
    "    index_of_highest_probability = np.argmax(val)\n",
    "    value_of_highest_probability = val[index_of_highest_probability]\n",
    "    prediction_table[index] = [\n",
    "        value_of_highest_probability, index_of_highest_probability,\n",
    "        ground_truth[index]\n",
    "    ]\n",
    "assert len(predictions) == len(ground_truth) == len(prediction_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0.99999356, 0, 0],\n",
       " 1: [0.9999957, 0, 0],\n",
       " 2: [0.99997973, 0, 0],\n",
       " 3: [0.98737216, 0, 0],\n",
       " 4: [0.9990239, 0, 0],\n",
       " 5: [0.8544114, 0, 0],\n",
       " 6: [0.9997974, 0, 0],\n",
       " 7: [0.9999895, 0, 0],\n",
       " 8: [0.9992786, 0, 0],\n",
       " 9: [0.99992216, 0, 0],\n",
       " 10: [0.9946024, 0, 0],\n",
       " 11: [0.9999589, 0, 0],\n",
       " 12: [0.999967, 0, 0],\n",
       " 13: [0.99969864, 0, 0],\n",
       " 14: [0.99994016, 0, 0],\n",
       " 15: [0.99999166, 0, 0],\n",
       " 16: [0.99998367, 0, 0],\n",
       " 17: [0.99998844, 0, 0],\n",
       " 18: [0.999861, 0, 0],\n",
       " 19: [0.98434246, 0, 0],\n",
       " 20: [0.9994708, 0, 0],\n",
       " 21: [0.9999635, 0, 0],\n",
       " 22: [0.97714806, 1, 0],\n",
       " 23: [0.99992025, 0, 0],\n",
       " 24: [0.99876106, 0, 0],\n",
       " 25: [0.94422436, 1, 0],\n",
       " 26: [0.97457576, 0, 0],\n",
       " 27: [0.9999409, 0, 0],\n",
       " 28: [0.9999118, 0, 0],\n",
       " 29: [0.9999949, 0, 0],\n",
       " 30: [0.9999746, 0, 0],\n",
       " 31: [0.9994424, 0, 0],\n",
       " 32: [0.9999945, 0, 0],\n",
       " 33: [0.99995375, 0, 0],\n",
       " 34: [0.99995315, 0, 0],\n",
       " 35: [0.9999976, 0, 0],\n",
       " 36: [0.99994767, 0, 0],\n",
       " 37: [0.99796236, 0, 0],\n",
       " 38: [0.9968901, 0, 0],\n",
       " 39: [0.9999746, 0, 0],\n",
       " 40: [0.99969816, 0, 0],\n",
       " 41: [0.9703976, 0, 0],\n",
       " 42: [0.8979808, 0, 0],\n",
       " 43: [0.9974197, 0, 0],\n",
       " 44: [0.92533493, 0, 0],\n",
       " 45: [0.9991346, 0, 0],\n",
       " 46: [0.9999857, 0, 0],\n",
       " 47: [0.9999627, 0, 0],\n",
       " 48: [0.99385977, 0, 0],\n",
       " 49: [0.9642121, 0, 0],\n",
       " 50: [0.99917114, 0, 0],\n",
       " 51: [0.81514204, 0, 0],\n",
       " 52: [0.9999212, 0, 0],\n",
       " 53: [0.9955329, 0, 0],\n",
       " 54: [0.9997193, 0, 0],\n",
       " 55: [0.9997713, 0, 0],\n",
       " 56: [0.9999958, 0, 0],\n",
       " 57: [0.9999974, 0, 0],\n",
       " 58: [0.99494237, 0, 0],\n",
       " 59: [0.9113943, 0, 0],\n",
       " 60: [0.99990714, 0, 0],\n",
       " 61: [0.9902366, 0, 0],\n",
       " 62: [0.9999286, 0, 0],\n",
       " 63: [0.9671026, 0, 0],\n",
       " 64: [0.905919, 0, 0],\n",
       " 65: [0.9993537, 0, 0],\n",
       " 66: [0.98792297, 0, 0],\n",
       " 67: [0.99875355, 0, 0],\n",
       " 68: [0.98235977, 0, 0],\n",
       " 69: [0.9997924, 0, 0],\n",
       " 70: [0.97964364, 0, 0],\n",
       " 71: [0.99933064, 0, 0],\n",
       " 72: [0.9995852, 0, 0],\n",
       " 73: [0.9998983, 0, 0],\n",
       " 74: [0.9994692, 0, 0],\n",
       " 75: [0.9913201, 0, 0],\n",
       " 76: [0.99997044, 0, 0],\n",
       " 77: [0.9998331, 0, 0],\n",
       " 78: [0.99193597, 0, 0],\n",
       " 79: [0.99986434, 0, 0],\n",
       " 80: [0.9984409, 0, 0],\n",
       " 81: [0.9623128, 0, 0],\n",
       " 82: [0.9984882, 0, 0],\n",
       " 83: [0.9984611, 0, 0],\n",
       " 84: [0.92469853, 1, 0],\n",
       " 85: [0.99997854, 0, 0],\n",
       " 86: [0.99996305, 0, 0],\n",
       " 87: [0.99646026, 0, 0],\n",
       " 88: [0.9999652, 0, 0],\n",
       " 89: [0.99996734, 0, 0],\n",
       " 90: [0.9644293, 0, 0],\n",
       " 91: [0.9995326, 0, 0],\n",
       " 92: [0.9990119, 0, 0],\n",
       " 93: [0.9952049, 0, 0],\n",
       " 94: [0.9999906, 0, 0],\n",
       " 95: [0.9999814, 0, 0],\n",
       " 96: [0.9998784, 0, 0],\n",
       " 97: [0.99971646, 0, 0],\n",
       " 98: [0.9050912, 1, 0],\n",
       " 99: [0.77912754, 0, 0],\n",
       " 100: [0.9998542, 0, 0],\n",
       " 101: [0.99793303, 0, 0],\n",
       " 102: [0.99998856, 0, 0],\n",
       " 103: [0.99998283, 0, 0],\n",
       " 104: [0.999884, 0, 0],\n",
       " 105: [0.9976555, 0, 0],\n",
       " 106: [0.9998398, 0, 0],\n",
       " 107: [0.99979585, 0, 0],\n",
       " 108: [0.9828944, 0, 0],\n",
       " 109: [0.9998915, 0, 0],\n",
       " 110: [0.97704643, 0, 0],\n",
       " 111: [0.9999585, 0, 0],\n",
       " 112: [0.9775513, 0, 0],\n",
       " 113: [0.9999794, 0, 0],\n",
       " 114: [0.9999659, 0, 0],\n",
       " 115: [0.9999083, 0, 0],\n",
       " 116: [0.99986863, 0, 0],\n",
       " 117: [0.9996269, 0, 0],\n",
       " 118: [0.9998348, 0, 0],\n",
       " 119: [0.99958557, 0, 0],\n",
       " 120: [0.9988568, 0, 0],\n",
       " 121: [0.9993074, 0, 0],\n",
       " 122: [0.9983981, 0, 0],\n",
       " 123: [0.995408, 0, 0],\n",
       " 124: [0.93818045, 0, 0],\n",
       " 125: [0.9929488, 0, 0],\n",
       " 126: [0.99999774, 0, 0],\n",
       " 127: [0.99729687, 0, 0],\n",
       " 128: [0.9999888, 0, 0],\n",
       " 129: [0.9998615, 0, 0],\n",
       " 130: [0.9999919, 0, 0],\n",
       " 131: [0.9983113, 0, 0],\n",
       " 132: [0.99999106, 0, 0],\n",
       " 133: [0.9996494, 0, 0],\n",
       " 134: [0.9999596, 0, 0],\n",
       " 135: [0.9999907, 0, 0],\n",
       " 136: [0.9977016, 0, 0],\n",
       " 137: [0.999956, 0, 0],\n",
       " 138: [0.9998585, 0, 0],\n",
       " 139: [0.990728, 0, 0],\n",
       " 140: [0.99976605, 0, 0],\n",
       " 141: [0.99974877, 0, 0],\n",
       " 142: [0.9996915, 0, 0],\n",
       " 143: [0.997399, 0, 0],\n",
       " 144: [0.9999839, 0, 0],\n",
       " 145: [0.99998057, 0, 0],\n",
       " 146: [0.99956554, 0, 0],\n",
       " 147: [0.9996044, 0, 0],\n",
       " 148: [0.9985245, 0, 0],\n",
       " 149: [0.99739325, 0, 0],\n",
       " 150: [0.998623, 0, 0],\n",
       " 151: [0.9999813, 0, 0],\n",
       " 152: [0.9994056, 0, 0],\n",
       " 153: [0.99866533, 0, 0],\n",
       " 154: [0.996977, 0, 0],\n",
       " 155: [0.9999827, 0, 0],\n",
       " 156: [0.9999472, 0, 0],\n",
       " 157: [0.9998944, 0, 0],\n",
       " 158: [0.9990976, 0, 0],\n",
       " 159: [0.99976045, 0, 0],\n",
       " 160: [0.98754764, 0, 0],\n",
       " 161: [0.99946445, 0, 0],\n",
       " 162: [0.99998975, 0, 0],\n",
       " 163: [0.9998611, 0, 0],\n",
       " 164: [0.9999194, 0, 0],\n",
       " 165: [0.9999242, 0, 0],\n",
       " 166: [0.9998011, 0, 0],\n",
       " 167: [0.9747444, 0, 0],\n",
       " 168: [0.99944204, 0, 0],\n",
       " 169: [0.9996722, 0, 0],\n",
       " 170: [0.9993175, 0, 0],\n",
       " 171: [0.9997328, 0, 0],\n",
       " 172: [0.8220269, 0, 0],\n",
       " 173: [0.99973756, 0, 0],\n",
       " 174: [0.999977, 0, 0],\n",
       " 175: [0.9990345, 0, 0],\n",
       " 176: [0.96623456, 0, 0],\n",
       " 177: [0.999527, 0, 0],\n",
       " 178: [0.99999714, 0, 0],\n",
       " 179: [0.99871886, 0, 0],\n",
       " 180: [0.99322, 0, 0],\n",
       " 181: [0.9990275, 0, 0],\n",
       " 182: [0.9945064, 0, 0],\n",
       " 183: [0.99961567, 0, 0],\n",
       " 184: [0.99999464, 0, 0],\n",
       " 185: [0.86078835, 0, 0],\n",
       " 186: [0.9926523, 0, 0],\n",
       " 187: [0.99936575, 0, 0],\n",
       " 188: [0.9974643, 0, 0],\n",
       " 189: [0.9996112, 0, 0],\n",
       " 190: [0.7066047, 0, 0],\n",
       " 191: [0.9480013, 0, 0],\n",
       " 192: [0.9952077, 0, 0],\n",
       " 193: [0.99130857, 0, 0],\n",
       " 194: [0.9999709, 0, 0],\n",
       " 195: [0.9999373, 0, 0],\n",
       " 196: [0.9963852, 0, 0],\n",
       " 197: [0.99810433, 0, 0],\n",
       " 198: [0.9995684, 0, 0],\n",
       " 199: [0.57636726, 0, 0],\n",
       " 200: [0.9999691, 0, 0],\n",
       " 201: [0.9814167, 0, 0],\n",
       " 202: [0.9999931, 0, 0],\n",
       " 203: [0.9662643, 0, 0],\n",
       " 204: [0.9910081, 0, 0],\n",
       " 205: [0.9998553, 0, 0],\n",
       " 206: [0.9999511, 0, 0],\n",
       " 207: [0.9998585, 0, 0],\n",
       " 208: [0.8843898, 0, 0],\n",
       " 209: [0.99483395, 0, 0],\n",
       " 210: [0.9999752, 0, 0],\n",
       " 211: [0.99992776, 0, 0],\n",
       " 212: [0.9998016, 0, 0],\n",
       " 213: [0.9994678, 0, 0],\n",
       " 214: [0.99995494, 0, 0],\n",
       " 215: [0.9998547, 0, 0],\n",
       " 216: [0.9999944, 0, 0],\n",
       " 217: [0.9999949, 0, 0],\n",
       " 218: [0.99972206, 0, 0],\n",
       " 219: [0.9960134, 0, 0],\n",
       " 220: [0.999959, 0, 0],\n",
       " 221: [0.9999628, 0, 0],\n",
       " 222: [0.99526536, 0, 0],\n",
       " 223: [0.9998851, 0, 0],\n",
       " 224: [0.7377299, 1, 0],\n",
       " 225: [0.9999337, 0, 0],\n",
       " 226: [0.9506316, 0, 0],\n",
       " 227: [0.9999652, 0, 0],\n",
       " 228: [0.99960357, 0, 0],\n",
       " 229: [0.99935013, 0, 0],\n",
       " 230: [0.9999336, 0, 0],\n",
       " 231: [0.99984634, 0, 0],\n",
       " 232: [0.9996809, 0, 0],\n",
       " 233: [0.99698085, 0, 0],\n",
       " 234: [0.9955707, 0, 0],\n",
       " 235: [0.9984596, 0, 0],\n",
       " 236: [0.9999386, 0, 0],\n",
       " 237: [0.9968575, 0, 0],\n",
       " 238: [0.9999931, 0, 0],\n",
       " 239: [0.9985279, 0, 0],\n",
       " 240: [0.999998, 0, 0],\n",
       " 241: [0.9961224, 0, 0],\n",
       " 242: [0.9998105, 0, 0],\n",
       " 243: [0.9957361, 0, 0],\n",
       " 244: [0.9987042, 0, 0],\n",
       " 245: [0.97812474, 0, 0],\n",
       " 246: [0.9801404, 0, 0],\n",
       " 247: [0.9999857, 0, 0],\n",
       " 248: [0.99998677, 0, 0],\n",
       " 249: [0.9999926, 0, 0],\n",
       " 250: [0.94148564, 1, 1],\n",
       " 251: [0.99999785, 1, 1],\n",
       " 252: [0.99896324, 1, 1],\n",
       " 253: [0.99952674, 1, 1],\n",
       " 254: [0.9630441, 1, 1],\n",
       " 255: [0.99988484, 1, 1],\n",
       " 256: [0.99995697, 1, 1],\n",
       " 257: [0.99997437, 1, 1],\n",
       " 258: [0.99988914, 1, 1],\n",
       " 259: [0.9329578, 1, 1],\n",
       " 260: [0.9999012, 1, 1],\n",
       " 261: [0.77558684, 1, 1],\n",
       " 262: [0.99947757, 1, 1],\n",
       " 263: [0.9967405, 1, 1],\n",
       " 264: [0.535079, 0, 1],\n",
       " 265: [0.9979679, 1, 1],\n",
       " 266: [0.9960603, 1, 1],\n",
       " 267: [0.9999951, 1, 1],\n",
       " 268: [0.98885196, 1, 1],\n",
       " 269: [0.9985409, 1, 1],\n",
       " 270: [0.99999857, 1, 1],\n",
       " 271: [0.99589926, 1, 1],\n",
       " 272: [0.9984806, 1, 1],\n",
       " 273: [0.8766461, 1, 1],\n",
       " 274: [0.9705603, 1, 1],\n",
       " 275: [0.9995173, 1, 1],\n",
       " 276: [0.9999932, 1, 1],\n",
       " 277: [0.9023799, 1, 1],\n",
       " 278: [0.9994443, 1, 1],\n",
       " 279: [0.99991596, 1, 1],\n",
       " 280: [0.999716, 1, 1],\n",
       " 281: [0.9988752, 1, 1],\n",
       " 282: [0.9191987, 1, 1],\n",
       " 283: [0.991336, 1, 1],\n",
       " 284: [0.99999714, 1, 1],\n",
       " 285: [0.9998173, 1, 1],\n",
       " 286: [0.9999907, 1, 1],\n",
       " 287: [0.99985456, 1, 1],\n",
       " 288: [0.9986834, 1, 1],\n",
       " 289: [0.9968393, 1, 1],\n",
       " 290: [0.99972457, 1, 1],\n",
       " 291: [0.96382326, 1, 1],\n",
       " 292: [0.99856216, 1, 1],\n",
       " 293: [0.98143286, 1, 1],\n",
       " 294: [0.99930704, 1, 1],\n",
       " 295: [0.9999472, 1, 1],\n",
       " 296: [0.9998012, 1, 1],\n",
       " 297: [0.99996686, 1, 1],\n",
       " 298: [0.9999794, 1, 1],\n",
       " 299: [0.9928625, 1, 1],\n",
       " 300: [0.9983144, 1, 1],\n",
       " 301: [0.9861215, 1, 1],\n",
       " 302: [0.98908335, 1, 1],\n",
       " 303: [0.99936074, 1, 1],\n",
       " 304: [0.9999391, 1, 1],\n",
       " 305: [0.9999778, 1, 1],\n",
       " 306: [0.9995478, 1, 1],\n",
       " 307: [0.99681336, 1, 1],\n",
       " 308: [0.9513411, 1, 1],\n",
       " 309: [0.99998486, 1, 1],\n",
       " 310: [0.99994886, 1, 1],\n",
       " 311: [0.99968684, 1, 1],\n",
       " 312: [0.9998357, 1, 1],\n",
       " 313: [0.99923944, 1, 1],\n",
       " 314: [0.999673, 1, 1],\n",
       " 315: [0.9996244, 1, 1],\n",
       " 316: [0.9228223, 1, 1],\n",
       " 317: [0.9958326, 1, 1],\n",
       " 318: [0.9490734, 1, 1],\n",
       " 319: [0.9904778, 1, 1],\n",
       " 320: [0.99993014, 1, 1],\n",
       " 321: [0.87049025, 1, 1],\n",
       " 322: [0.9892069, 1, 1],\n",
       " 323: [0.9947096, 1, 1],\n",
       " 324: [0.9998287, 1, 1],\n",
       " 325: [0.9997614, 1, 1],\n",
       " 326: [0.99961543, 1, 1],\n",
       " 327: [0.9997396, 1, 1],\n",
       " 328: [0.9997814, 1, 1],\n",
       " 329: [0.9927925, 1, 1],\n",
       " 330: [0.999997, 1, 1],\n",
       " 331: [0.9992899, 1, 1],\n",
       " 332: [0.9993375, 1, 1],\n",
       " 333: [0.9910417, 1, 1],\n",
       " 334: [0.9999256, 1, 1],\n",
       " 335: [0.9999645, 1, 1],\n",
       " 336: [0.9937197, 1, 1],\n",
       " 337: [0.97200686, 1, 1],\n",
       " 338: [0.99973613, 1, 1],\n",
       " 339: [0.99980384, 1, 1],\n",
       " 340: [0.99127686, 1, 1],\n",
       " 341: [0.9905155, 1, 1],\n",
       " 342: [0.99991345, 1, 1],\n",
       " 343: [0.99999607, 1, 1],\n",
       " 344: [0.999997, 1, 1],\n",
       " 345: [0.9993814, 1, 1],\n",
       " 346: [0.99501145, 1, 1],\n",
       " 347: [0.50449854, 1, 1],\n",
       " 348: [0.9994479, 1, 1],\n",
       " 349: [0.9995376, 1, 1],\n",
       " 350: [0.97807455, 1, 1],\n",
       " 351: [0.9851597, 1, 1],\n",
       " 352: [0.99759275, 1, 1],\n",
       " 353: [0.99999905, 1, 1],\n",
       " 354: [0.99974793, 1, 1],\n",
       " 355: [0.9999441, 1, 1],\n",
       " 356: [0.99871504, 1, 1],\n",
       " 357: [0.97640765, 1, 1],\n",
       " 358: [0.9999999, 1, 1],\n",
       " 359: [0.99998, 1, 1],\n",
       " 360: [0.99170154, 1, 1],\n",
       " 361: [0.9988972, 1, 1],\n",
       " 362: [0.84681374, 1, 1],\n",
       " 363: [0.9996544, 1, 1],\n",
       " 364: [0.99957913, 1, 1],\n",
       " 365: [0.92318773, 1, 1],\n",
       " 366: [0.56646967, 1, 1],\n",
       " 367: [0.9976318, 1, 1],\n",
       " 368: [0.93286145, 1, 1],\n",
       " 369: [0.9722855, 1, 1],\n",
       " 370: [0.9868129, 1, 1],\n",
       " 371: [0.9927676, 1, 1],\n",
       " 372: [0.9976407, 1, 1],\n",
       " 373: [0.99997485, 1, 1],\n",
       " 374: [0.9999149, 1, 1],\n",
       " 375: [0.9294809, 1, 1],\n",
       " 376: [0.999998, 1, 1],\n",
       " 377: [0.9992755, 1, 1],\n",
       " 378: [0.72164, 1, 1],\n",
       " 379: [0.9999713, 1, 1],\n",
       " 380: [0.9999666, 1, 1],\n",
       " 381: [0.99672276, 1, 1],\n",
       " 382: [0.9998778, 1, 1],\n",
       " 383: [0.99682885, 1, 1],\n",
       " 384: [0.9999416, 1, 1],\n",
       " 385: [0.99889344, 1, 1],\n",
       " 386: [0.99983597, 1, 1],\n",
       " 387: [0.9549744, 0, 1],\n",
       " 388: [0.99991524, 1, 1],\n",
       " 389: [0.9988324, 1, 1],\n",
       " 390: [0.9998852, 1, 1],\n",
       " 391: [0.6777396, 1, 1],\n",
       " 392: [0.90085465, 1, 1],\n",
       " 393: [0.99994624, 1, 1],\n",
       " 394: [0.9999131, 1, 1],\n",
       " 395: [0.987452, 1, 1],\n",
       " 396: [0.99796677, 1, 1],\n",
       " 397: [0.97583157, 1, 1],\n",
       " 398: [0.99861777, 1, 1],\n",
       " 399: [0.99807763, 1, 1],\n",
       " 400: [0.9983791, 1, 1],\n",
       " 401: [0.99989283, 1, 1],\n",
       " 402: [0.9993548, 1, 1],\n",
       " 403: [0.99716467, 1, 1],\n",
       " 404: [0.99997115, 1, 1],\n",
       " 405: [0.6001705, 0, 1],\n",
       " 406: [0.9986889, 1, 1],\n",
       " 407: [0.999655, 1, 1],\n",
       " 408: [0.9998374, 1, 1],\n",
       " 409: [0.9999176, 1, 1],\n",
       " 410: [0.9997751, 1, 1],\n",
       " 411: [0.9971323, 1, 1],\n",
       " 412: [0.9978927, 1, 1],\n",
       " 413: [0.99912137, 1, 1],\n",
       " 414: [0.9990779, 1, 1],\n",
       " 415: [0.99118364, 1, 1],\n",
       " 416: [0.99209, 1, 1],\n",
       " 417: [0.9991178, 1, 1],\n",
       " 418: [0.9999672, 1, 1],\n",
       " 419: [0.98941237, 1, 1],\n",
       " 420: [0.77375185, 0, 1],\n",
       " 421: [0.99995124, 1, 1],\n",
       " 422: [0.99930143, 1, 1],\n",
       " 423: [0.9982168, 1, 1],\n",
       " 424: [0.99992824, 1, 1],\n",
       " 425: [0.9942977, 1, 1],\n",
       " 426: [0.99079835, 1, 1],\n",
       " 427: [0.99985325, 1, 1],\n",
       " 428: [0.7562766, 1, 1],\n",
       " 429: [0.99223983, 1, 1],\n",
       " 430: [0.99997735, 1, 1],\n",
       " 431: [0.74927264, 1, 1],\n",
       " 432: [0.9836039, 1, 1],\n",
       " 433: [0.999819, 1, 1],\n",
       " 434: [0.99993014, 1, 1],\n",
       " 435: [0.99855596, 1, 1],\n",
       " 436: [0.6494715, 0, 1],\n",
       " 437: [0.9999342, 1, 1],\n",
       " 438: [0.9997141, 1, 1],\n",
       " 439: [0.71776634, 0, 1],\n",
       " 440: [0.99968004, 1, 1],\n",
       " 441: [0.9949805, 1, 1],\n",
       " 442: [0.99891675, 1, 1],\n",
       " 443: [0.9999914, 1, 1],\n",
       " 444: [0.91396135, 0, 1],\n",
       " 445: [0.99995077, 1, 1],\n",
       " 446: [0.97802335, 1, 1],\n",
       " 447: [0.9999931, 1, 1],\n",
       " 448: [0.9945549, 1, 1],\n",
       " 449: [0.92427945, 1, 1],\n",
       " 450: [0.9997329, 1, 1],\n",
       " 451: [0.99903595, 1, 1],\n",
       " 452: [0.9999621, 1, 1],\n",
       " 453: [0.99995077, 1, 1],\n",
       " 454: [0.9998442, 1, 1],\n",
       " 455: [0.97818494, 1, 1],\n",
       " 456: [0.9984756, 1, 1],\n",
       " 457: [0.9995906, 1, 1],\n",
       " 458: [0.99962044, 1, 1],\n",
       " 459: [0.9985049, 1, 1],\n",
       " 460: [0.9792627, 1, 1],\n",
       " 461: [0.96962816, 1, 1],\n",
       " 462: [0.99997544, 1, 1],\n",
       " 463: [0.9991241, 1, 1],\n",
       " 464: [0.9471674, 1, 1],\n",
       " 465: [0.99999833, 1, 1],\n",
       " 466: [0.9999764, 1, 1],\n",
       " 467: [0.9999052, 1, 1],\n",
       " 468: [0.9805233, 1, 1],\n",
       " 469: [0.999795, 1, 1],\n",
       " 470: [0.9276859, 1, 1],\n",
       " 471: [0.99956924, 1, 1],\n",
       " 472: [0.591107, 0, 1],\n",
       " 473: [0.99975413, 1, 1],\n",
       " 474: [0.99110806, 1, 1],\n",
       " 475: [0.999944, 1, 1],\n",
       " 476: [0.99933475, 1, 1],\n",
       " 477: [0.9607726, 1, 1],\n",
       " 478: [0.99983096, 1, 1],\n",
       " 479: [0.9767347, 1, 1],\n",
       " 480: [0.9919648, 1, 1],\n",
       " 481: [0.99894565, 1, 1],\n",
       " 482: [0.9999914, 1, 1],\n",
       " 483: [0.9999963, 1, 1],\n",
       " 484: [0.9997321, 1, 1],\n",
       " 485: [0.9997708, 1, 1],\n",
       " 486: [0.9999063, 1, 1],\n",
       " 487: [0.9995776, 1, 1],\n",
       " 488: [0.9997818, 1, 1],\n",
       " 489: [0.9998591, 1, 1],\n",
       " 490: [0.9999906, 1, 1],\n",
       " 491: [0.99368036, 1, 1],\n",
       " 492: [0.99853694, 1, 1],\n",
       " 493: [0.99154085, 1, 1],\n",
       " 494: [0.8157459, 1, 1],\n",
       " 495: [0.99956053, 1, 1],\n",
       " 496: [0.99888605, 1, 1],\n",
       " 497: [0.9992256, 1, 1],\n",
       " 498: [0.9999248, 1, 1],\n",
       " 499: [0.99014574, 1, 1]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_table # (probability, prediction, truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
